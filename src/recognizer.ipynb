{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "you need [git clone https://github.com/comicom/hand-gesture-recognition/tree/master]\n",
    "And then, replace \"recognizer.ipynb\" to control folder or update PATH in this code\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras import layers\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "BASE_PATH = \"../model\"\n",
    "MODEL_PATH = \"/keras/hdf5/default_model.h5\"\n",
    "WEIGHT_PATH = \"/keras/weight/default_weight.ckpt\"\n",
    "LABEL = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\n",
    "# FOR SIGN-LANGUAGE\n",
    "#LABEL = ['A','B','C','D','E','F','G','H','I','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kerasModel:\n",
    "    \n",
    "    def __init__ (self, base_path=BASE_PATH, model_path=MODEL_PATH, weight_path=WEIGHT_PATH):\n",
    "        self.model = load_model(base_path + model_path,compile=False)\n",
    "        self.weight = self.model.load_weights(base_path + weight_path)\n",
    "        self.output_shape = [layer.output_shape for layer in self.model.layers[:][:]]\n",
    "        self.model.summary()\n",
    "        print(base_path + model_path)\n",
    "        print(base_path + weight_path)\n",
    "\n",
    "    def state(self):\n",
    "        layer_outputs = [layer.output for layer in self.model.layers[:]]\n",
    "        layer_names = [layer.name for layer in self.model.layers[:][:]]\n",
    "        layer_output_shape = [layer.output_shape for layer in self.model.layers[:][:]]\n",
    "        output_shape = [output_shape for output_shape in self.output_shape[-1][1:]]\n",
    "        print(\"layer outputs Check: \", [i for i in layer_outputs])\n",
    "        print(\"layer names Check: \", layer_names)\n",
    "        print(\"layer output_shape Check: \", layer_output_shape[:][:])\n",
    "        \n",
    "    def prediction(self,image):\n",
    "        size = (self.output_shape[0][-1][1],self.output_shape[0][-1][2])\n",
    "        output_shape = [output_shape for output_shape in self.output_shape[-1][1:]]\n",
    "        resizedImage = np.expand_dims(cv2.resize(image, size),axis=0)\n",
    "        if resizedImage.ndim != 4:\n",
    "            resizedImage = np.expand_dims(resizedImage,axis=3)\n",
    "        predict = self.model.predict(resizedImage)\n",
    "        \n",
    "        return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class realtimeRecognition:\n",
    "    def __init__ (self, camID=0, base_path=BASE_PATH, model_path=MODEL_PATH, weight_path=WEIGHT_PATH):\n",
    "        self.camID = camID\n",
    "        self.cap = cv2.VideoCapture(self.camID)\n",
    "        self.bg = None\n",
    "        self.bgState = False\n",
    "        self.kernel = np.ones((3,3),np.uint8)\n",
    "        self.positions = {\n",
    "            \"hand_pose\" : (15,40), #hand pose text\n",
    "            \"fps\" : (15,20), #fps counter\n",
    "            \"null_pos\" : (200,200) #used as null point for mous control\n",
    "        }\n",
    "        self.ROI = {\n",
    "            \"top\" : 10,\n",
    "            \"right\" : 350,\n",
    "            \"bottom\" : 255,\n",
    "            \"left\" : 590,\n",
    "            \"COLOR\" : (0,255,0)\n",
    "        }\n",
    "        self.foreground_display = []\n",
    "        self.mask_img = []\n",
    "        self.roi = []\n",
    "        self.h = []\n",
    "        self.model = kerasModel(base_path=base_path, model_path=model_path, weight_path=weight_path)\n",
    "    \n",
    "    def __del__(self):\n",
    "        self.cap.release\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    #Execute programe\n",
    "    def run(self):\n",
    "        # Capture > Process > Display loop\n",
    "        while True:\n",
    "            ### 1. Capture\n",
    "            self.rect, self.frame = self.cap.read()\n",
    "            self.frame = cv2.flip(self.frame, 1)\n",
    "            self.display = self.frame.copy()\n",
    "            ### 2. Process\n",
    "            self.roi = self.frame[self.ROI[\"top\"]:self.ROI[\"bottom\"],\n",
    "                                  self.ROI[\"right\"]:self.ROI[\"left\"]]\n",
    "            self.foreground_display, self.mask_img = self.capBackground(self.frame)\n",
    "  \n",
    "            ### 3. Display\n",
    "            cv2.rectangle(self.display,\n",
    "                          (self.ROI[\"left\"],self.ROI[\"top\"]),\n",
    "                          (self.ROI[\"right\"],self.ROI[\"bottom\"]),\n",
    "                          self.ROI[\"COLOR\"], 2)\n",
    "            cv2.imshow(\"display\",self.display)\n",
    "            \n",
    "            if self.foreground_display is not None:\n",
    "                cv2.imshow(\"basic\",self.roi)\n",
    "                cv2.imshow(\"forground_display\", self.foreground_display)\n",
    "                cv2.imshow(\"mask_img\", self.mask_img)\n",
    "                self.h = self.roi*((cv2.cvtColor(self.foreground_display,cv2.COLOR_GRAY2RGB)/255).astype(\"uint8\"))\n",
    "                cv2.imshow(\"masked image\",self.h)\n",
    "                #cv2.imshow(\"test\",(cv2.cvtColor(self.foreground_display,cv2.COLOR_GRAY2RGB)/255).astype(\"uint8\"))\n",
    "            \n",
    "            ## 4. Free up memory\n",
    "            k = cv2.waitKey(1)\n",
    "            \n",
    "            self.waitK(k)\n",
    "    \n",
    "    #Predict using Keras\n",
    "    def kerasPrediction(self,image):\n",
    "        #prediction\n",
    "        predict = self.model.prediction(image)\n",
    "        predi = predict.argmax()\n",
    "        result = LABEL[predi]\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    #Capture background for using find the difference between the background frame and current frame \n",
    "    def capBackground(self,image):\n",
    "        if self.bg is None:\n",
    "            cv2.putText(self.display,\n",
    "                        \"Press 'r' to reset the foreground extraction.\",\n",
    "                        self.positions[\"hand_pose\"],\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.75, (0, 127, 64), 2)\n",
    "            foreground_display = None\n",
    "            mask_img = None\n",
    "        else :\n",
    "            foreground, mask, mask_img = self.extractForeground(image)\n",
    "            foreground_display = foreground.copy()\n",
    "        \n",
    "        return foreground_display, mask_img\n",
    "        \n",
    "            \n",
    "    def extractForeground(self,image):\n",
    "        # Find the absolute difference between the background frame and current frame\n",
    "        diff = cv2.absdiff(self.bg, image)\n",
    "        mask = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #threshold the mask\n",
    "        _, thresh = cv2.threshold(mask, 15, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        #img preprocessing\n",
    "#         opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, self.kernel)\n",
    "#         closing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, self.kernel)\n",
    "        ero = cv2.erode(thresh,np.ones((3,3)))\n",
    "        dil = cv2.dilate(ero,np.ones((5,5)))\n",
    "        ###Helper function for applying a mask to an array\n",
    "        forground = dil[self.ROI[\"top\"]:self.ROI[\"bottom\"],\n",
    "                            self.ROI[\"right\"]:self.ROI[\"left\"]]\n",
    "        mask_img = mask[self.ROI[\"top\"]:self.ROI[\"bottom\"],\n",
    "                        self.ROI[\"right\"]:self.ROI[\"left\"]]\n",
    "        return forground, mask, mask_img\n",
    "    \n",
    "    #Capture training images\n",
    "    def capImage(self,num):\n",
    "        if num == 0:\n",
    "            #capture single image\n",
    "            print(\"capImage 0: single image\")\n",
    "        elif num == 1:\n",
    "            #capture mutiple images\n",
    "            print(\"capImage 0: mutiple image\")\n",
    "        else:\n",
    "            print(\"realtimeRcognition.capImage <<ERROR>>\")\n",
    "    \n",
    "    #WaitKey\n",
    "    def waitK(self,k):\n",
    "        if k == ord(\"q\"):\n",
    "            self.cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "        elif k == ord(\"r\"):\n",
    "            self.bg = self.frame.copy()\n",
    "            self.bgState = True\n",
    "            print(\"realtimeRecognizer.extractForeground OK\")\n",
    "            print(\"realtimeRecognizer.capBackground OK\")\n",
    "#         elif k == ord(\"c\"):\n",
    "#             self.capImage(0)\n",
    "#         elif k == ord(\"m\"):\n",
    "#             self.capImage(1)\n",
    "        elif k == ord(\"p\"):\n",
    "            if self.bgState == True :\n",
    "                if self.model.output_shape[0][-1][-1] == 3 :\n",
    "                    result = self.kerasPrediction((self.h)/255.)\n",
    "                    result = self.kerasPrediction((self.roi)/255.)\n",
    "                elif self.model.output_shape[0][-1][-1] == 1 :\n",
    "                    self.roi = cv2.cvtColor(self.roi,cv2.COLOR_RGB2GRAY)\n",
    "                    result = self.kerasPrediction(self.roi/255.)\n",
    "                else :\n",
    "                    print(self.model.output_shape[0][-1],self.model.output_shape[0])\n",
    "                    result = \"error!\"\n",
    "                    \n",
    "                print(\"result:\",result)\n",
    "\n",
    "            else :\n",
    "                print(\"Press r first\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 26)                3354      \n",
      "=================================================================\n",
      "Total params: 247,002\n",
      "Trainable params: 247,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "../model/keras/hdf5/handgesture-raw-200214-28x28x3.h5\n",
      "../model/keras/weight/handgesture-raw-200214-28x28x3-0004.ckpt\n",
      "realtimeRecognizer.extractForeground OK\n",
      "realtimeRecognizer.capBackground OK\n",
      "result: T\n",
      "result: I\n",
      "result: D\n",
      "result: D\n",
      "result: F\n",
      "result: C\n",
      "result: D\n",
      "result: U\n",
      "result: U\n",
      "result: B\n",
      "result: B\n",
      "result: U\n",
      "result: U\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: U\n",
      "result: U\n",
      "result: U\n",
      "result: L\n",
      "result: L\n",
      "result: L\n",
      "result: L\n",
      "result: L\n",
      "result: T\n",
      "result: L\n",
      "result: L\n",
      "result: L\n",
      "result: L\n",
      "result: S\n",
      "result: S\n",
      "result: G\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: L\n",
      "result: L\n",
      "result: L\n",
      "result: B\n",
      "result: L\n",
      "result: B\n",
      "result: B\n",
      "result: I\n",
      "result: I\n",
      "result: G\n",
      "result: E\n",
      "result: T\n",
      "result: L\n",
      "result: T\n",
      "result: P\n",
      "result: S\n",
      "result: T\n",
      "result: E\n",
      "result: E\n",
      "result: T\n",
      "result: T\n",
      "result: T\n",
      "result: T\n",
      "result: T\n",
      "result: E\n",
      "result: F\n",
      "result: E\n",
      "result: E\n",
      "result: T\n",
      "result: T\n",
      "result: E\n",
      "result: T\n",
      "result: E\n",
      "result: E\n",
      "result: F\n",
      "result: T\n",
      "result: E\n",
      "result: F\n",
      "result: E\n",
      "result: B\n",
      "result: E\n",
      "result: E\n",
      "result: E\n",
      "result: E\n",
      "result: F\n",
      "result: K\n",
      "result: E\n",
      "result: U\n",
      "result: E\n",
      "result: E\n",
      "result: C\n",
      "result: C\n",
      "result: C\n",
      "result: C\n",
      "result: C\n",
      "result: C\n",
      "result: D\n",
      "result: D\n",
      "result: D\n",
      "result: D\n",
      "result: D\n",
      "result: D\n",
      "result: D\n",
      "result: D\n",
      "result: D\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: D\n",
      "result: D\n",
      "result: D\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: K\n",
      "result: B\n",
      "result: B\n",
      "result: D\n",
      "result: B\n",
      "result: B\n",
      "result: D\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: C\n",
      "result: C\n",
      "result: C\n",
      "result: C\n",
      "result: C\n",
      "result: B\n",
      "result: D\n",
      "result: D\n",
      "result: D\n",
      "result: L\n",
      "result: L\n",
      "result: L\n",
      "result: B\n",
      "result: D\n",
      "result: B\n",
      "result: B\n",
      "result: C\n",
      "result: C\n",
      "result: C\n",
      "result: C\n",
      "result: C\n",
      "result: C\n",
      "result: C\n",
      "result: B\n",
      "result: C\n",
      "result: F\n",
      "result: E\n",
      "result: E\n",
      "result: E\n",
      "result: E\n",
      "result: E\n",
      "result: E\n",
      "result: A\n",
      "result: E\n",
      "result: E\n",
      "result: T\n",
      "result: T\n",
      "result: M\n",
      "result: L\n",
      "result: M\n",
      "result: M\n",
      "result: D\n",
      "result: D\n",
      "result: D\n",
      "result: B\n",
      "result: K\n",
      "result: K\n",
      "result: B\n",
      "result: C\n",
      "result: L\n",
      "result: T\n",
      "result: T\n",
      "result: F\n",
      "result: F\n",
      "result: U\n",
      "result: B\n",
      "result: B\n",
      "result: D\n",
      "result: D\n",
      "result: D\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: K\n",
      "result: B\n",
      "result: B\n",
      "result: K\n",
      "result: K\n",
      "result: K\n",
      "result: L\n",
      "result: L\n",
      "result: F\n",
      "result: C\n",
      "result: C\n",
      "result: C\n",
      "result: K\n",
      "result: F\n",
      "result: F\n",
      "result: B\n",
      "result: C\n",
      "result: B\n",
      "result: L\n",
      "result: C\n",
      "result: B\n",
      "result: B\n",
      "result: K\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: D\n",
      "result: Q\n",
      "result: B\n",
      "result: K\n",
      "result: L\n",
      "result: L\n",
      "result: L\n",
      "result: L\n",
      "result: L\n",
      "result: L\n",
      "result: L\n",
      "result: L\n",
      "result: L\n",
      "result: D\n",
      "result: L\n",
      "result: L\n",
      "result: L\n",
      "result: L\n",
      "result: L\n",
      "result: D\n",
      "result: D\n",
      "result: D\n",
      "result: F\n",
      "result: F\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: U\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: T\n",
      "result: L\n",
      "result: L\n",
      "result: L\n",
      "result: L\n",
      "result: B\n",
      "result: B\n",
      "result: U\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: L\n",
      "result: L\n",
      "result: L\n",
      "result: L\n",
      "result: L\n",
      "result: L\n",
      "result: L\n",
      "result: D\n",
      "result: D\n",
      "result: D\n",
      "result: D\n",
      "result: K\n",
      "result: K\n",
      "result: K\n",
      "result: D\n",
      "result: D\n",
      "result: D\n",
      "result: D\n",
      "result: D\n",
      "result: D\n",
      "result: D\n",
      "result: D\n",
      "result: D\n",
      "result: D\n",
      "result: D\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: C\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: C\n",
      "result: C\n",
      "result: B\n",
      "result: D\n",
      "result: D\n",
      "result: D\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: B\n",
      "result: C\n",
      "result: C\n",
      "result: E\n",
      "result: E\n",
      "result: C\n",
      "result: C\n",
      "result: C\n",
      "result: K\n",
      "result: C\n",
      "result: B\n",
      "result: F\n",
      "result: F\n",
      "result: D\n",
      "result: D\n",
      "result: D\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #recognizer = realtimeRecognition()\n",
    "    recognizer = realtimeRecognition(model_path=\"/keras/hdf5/handgesture-raw-200214-28x28x3.h5\",weight_path=\"/keras/weight/handgesture-raw-200214-28x28x3-0004.ckpt\")\n",
    "    recognizer.run()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
