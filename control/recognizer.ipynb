{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "you need [git clone https://github.com/comicom/hand-gesture-recognition/tree/master]\n",
    "And then, replace \"recognizer.ipynb\" to control folder or update PATH in this code\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras import layers\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "BASE_PATH = \"../model\"\n",
    "MODEL_PATH = \"/keras/hdf5/default_model.h5\"\n",
    "WEIGHT_PATH = \"/keras/weight/default_weight.ckpt\"\n",
    "#LABEL = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\n",
    "# FOR SIGN-LANGUAGE\n",
    "LABEL = ['A','B','C','D','E','F','G','H','I','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kerasModel:\n",
    "    \n",
    "    def __init__ (self, base_path=BASE_PATH, model_path=MODEL_PATH, weight_path=WEIGHT_PATH):\n",
    "        self.model = load_model(base_path + model_path,compile=False)\n",
    "        self.weight = self.model.load_weights(base_path + weight_path)\n",
    "        self.output_shape = [layer.output_shape for layer in self.model.layers[:][:]]\n",
    "        self.model.summary()\n",
    "        print(base_path + model_path)\n",
    "        print(base_path + weight_path)\n",
    "\n",
    "    def state(self):\n",
    "        layer_outputs = [layer.output for layer in self.model.layers[:]]\n",
    "        layer_names = [layer.name for layer in self.model.layers[:][:]]\n",
    "        layer_output_shape = [layer.output_shape for layer in self.model.layers[:][:]]\n",
    "        output_shape = [output_shape for output_shape in self.output_shape[-1][1:]]\n",
    "        print(\"layer outputs Check: \", [i for i in layer_outputs])\n",
    "        print(\"layer names Check: \", layer_names)\n",
    "        print(\"layer output_shape Check: \", layer_output_shape[:][:])\n",
    "        \n",
    "    def prediction(self,image):\n",
    "        size = (self.output_shape[0][1],self.output_shape[0][2])\n",
    "        output_shape = [output_shape for output_shape in self.output_shape[-1][1:]]\n",
    "        resizedImage = np.expand_dims(cv2.resize(image, size),axis=0)\n",
    "        if resizedImage.ndim != 4:\n",
    "            resizedImage = np.expand_dims(resizedImage,axis=3)\n",
    "        predict = self.model.predict(resizedImage)\n",
    "        \n",
    "        return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class realtimeRecognition:\n",
    "    def __init__ (self, camID=0, base_path=BASE_PATH, model_path=MODEL_PATH, weight_path=WEIGHT_PATH):\n",
    "        self.camID = camID\n",
    "        self.cap = cv2.VideoCapture(self.camID)\n",
    "        self.bg = None\n",
    "        self.bgState = False\n",
    "        self.kernel = np.ones((3,3),np.uint8)\n",
    "        self.positions = {\n",
    "            \"hand_pose\" : (15,40), #hand pose text\n",
    "            \"fps\" : (15,20), #fps counter\n",
    "            \"null_pos\" : (200,200) #used as null point for mous control\n",
    "        }\n",
    "        self.ROI = {\n",
    "            \"top\" : 10,\n",
    "            \"right\" : 350,\n",
    "            \"bottom\" : 255,\n",
    "            \"left\" : 590,\n",
    "            \"COLOR\" : (0,255,0)\n",
    "        }\n",
    "        self.foreground_display = []\n",
    "        self.mask_img = []\n",
    "        self.roi = []\n",
    "        self.model = kerasModel(base_path=base_path, model_path=model_path, weight_path=weight_path)\n",
    "    \n",
    "    def __del__(self):\n",
    "        self.cap.release\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    #Execute programe\n",
    "    def run(self):\n",
    "        # Capture > Process > Display loop\n",
    "        while True:\n",
    "            ### 1. Capture\n",
    "            self.rect, self.frame = self.cap.read()\n",
    "            self.frame = cv2.flip(self.frame, 1)\n",
    "            self.display = self.frame.copy()\n",
    "            ### 2. Process\n",
    "            self.roi = self.frame[self.ROI[\"top\"]:self.ROI[\"bottom\"],\n",
    "                                  self.ROI[\"right\"]:self.ROI[\"left\"]]\n",
    "            self.foreground_display, self.mask_img = self.capBackground(self.frame)\n",
    "  \n",
    "            ### 3. Display\n",
    "            cv2.rectangle(self.display,\n",
    "                          (self.ROI[\"left\"],self.ROI[\"top\"]),\n",
    "                          (self.ROI[\"right\"],self.ROI[\"bottom\"]),\n",
    "                          self.ROI[\"COLOR\"], 2)\n",
    "            cv2.imshow(\"display\",self.display)\n",
    "            \n",
    "            if self.foreground_display is not None:\n",
    "                cv2.imshow(\"basic\",self.roi)\n",
    "                cv2.imshow(\"forground_display\", self.foreground_display)\n",
    "                cv2.imshow(\"mask_img\", self.mask_img)\n",
    "            \n",
    "            ## 4. Free up memory\n",
    "            k = cv2.waitKey(1)\n",
    "            \n",
    "            self.waitK(k)\n",
    "    \n",
    "    #Predict using Keras\n",
    "    def kerasPrediction(self,image):\n",
    "        #prediction\n",
    "        predict = self.model.prediction(image)\n",
    "        predi = predict.argmax()\n",
    "        result = LABEL[predi]\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    #Capture background for using find the difference between the background frame and current frame \n",
    "    def capBackground(self,image):\n",
    "        if self.bg is None:\n",
    "            cv2.putText(self.display,\n",
    "                        \"Press 'r' to reset the foreground extraction.\",\n",
    "                        self.positions[\"hand_pose\"],\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.75, (0, 127, 64), 2)\n",
    "            foreground_display = None\n",
    "            mask_img = None\n",
    "        else :\n",
    "            foreground, mask, mask_img = self.extractForeground(image)\n",
    "            foreground_display = foreground.copy()\n",
    "        \n",
    "        return foreground_display, mask_img\n",
    "        \n",
    "            \n",
    "    def extractForeground(self,image):\n",
    "        # Find the absolute difference between the background frame and current frame\n",
    "        diff = cv2.absdiff(self.bg, image)\n",
    "        mask = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #threshold the mask\n",
    "        _, thresh = cv2.threshold(mask, 25, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        #img preprocessing\n",
    "        opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, self.kernel)\n",
    "        closing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, self.kernel)\n",
    "        \n",
    "        ###Helper function for applying a mask to an array\n",
    "        forground = closing[self.ROI[\"top\"]:self.ROI[\"bottom\"],\n",
    "                            self.ROI[\"right\"]:self.ROI[\"left\"]]\n",
    "        mask_img = mask[self.ROI[\"top\"]:self.ROI[\"bottom\"],\n",
    "                        self.ROI[\"right\"]:self.ROI[\"left\"]]\n",
    "        return forground, mask, mask_img\n",
    "    \n",
    "    #Capture training images\n",
    "    def capImage(self,num):\n",
    "        if num == 0:\n",
    "            #capture single image\n",
    "            print(\"capImage 0: single image\")\n",
    "        elif num == 1:\n",
    "            #capture mutiple images\n",
    "            print(\"capImage 0: mutiple image\")\n",
    "        else:\n",
    "            print(\"realtimeRcognition.capImage <<ERROR>>\")\n",
    "    \n",
    "    #WaitKey\n",
    "    def waitK(self,k):\n",
    "        if k == ord(\"q\"):\n",
    "            self.cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "        elif k == ord(\"r\"):\n",
    "            self.bg = self.frame.copy()\n",
    "            self.bgState = True\n",
    "            print(\"realtimeRecognizer.extractForeground OK\")\n",
    "            print(\"realtimeRecognizer.capBackground OK\")\n",
    "#         elif k == ord(\"c\"):\n",
    "#             self.capImage(0)\n",
    "#         elif k == ord(\"m\"):\n",
    "#             self.capImage(1)\n",
    "        elif k == ord(\"p\"):\n",
    "            if self.bgState == True :\n",
    "                if self.model.output_shape[0][-1] == 3 :\n",
    "                    result = self.kerasPrediction(self.roi)\n",
    "                elif self.model.output_shape[0][-1] == 1 :\n",
    "                    self.roi = cv2.cvtColor(self.roi,cv2.COLOR_RGB2GRAY)\n",
    "                    result = self.kerasPrediction(self.roi/255.)\n",
    "                else :\n",
    "                    result = \"error!\"\n",
    "                    \n",
    "                print(\"basic:\",result)\n",
    "\n",
    "            else :\n",
    "                print(\"Press r first\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #recognizer = realtimeRecognition()\n",
    "    recognizer = realtimeRecognition(model_path=\"/keras/hdf5/sign-language.h5\",weight_path=\"/keras/weight/sign-language_cp-050.ckpt\")\n",
    "    recognizer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
